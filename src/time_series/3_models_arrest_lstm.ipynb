{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from numpy import arange\n",
    "from pandas import read_csv, DataFrame, Series\n",
    "from matplotlib.pyplot import savefig\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join('..', 'utils'))\n",
    "sys.path.append(utils_path)\n",
    "\n",
    "from dslabs_functions import ts_aggregation_by, series_train_test_split, plot_forecasting_eval, plot_forecasting_series, series_train_test_split\n",
    "from dslabs_functions import HEIGHT, plot_multiline_chart\n",
    "from dslabs_functions import FORECAST_MEASURES, DELTA_IMPROVE, plot_multiline_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.abspath(os.path.join('..','..', 'data_copy/forecast_ny_arrests.csv'))\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"File not found\")\n",
    "    data_path = os.path.abspath(os.path.join('..','..', 'data/f_s_forecast_ny_arrests.csv'))\n",
    "\n",
    "def load_data(data_path):\n",
    "    data: DataFrame = read_csv(\n",
    "        data_path,\n",
    "        index_col=\"Date\",\n",
    "        sep=\";\",\n",
    "        decimal=\".\",\n",
    "        parse_dates=True,\n",
    "        infer_datetime_format=True,\n",
    "    )\n",
    "    return data\n",
    "\n",
    "all_data = load_data(data_path)\n",
    "file_tag = \"ARREST\"\n",
    "target = \"Manhattan\"\n",
    "\n",
    "\n",
    "\n",
    "data = all_data[[target]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "def dataframe_train_test_split(data: DataFrame, trn_pct: float = 0.90) -> tuple[DataFrame, DataFrame]:\n",
    "    trn_size = int(len(data) * trn_pct)\n",
    "    train = data.iloc[:trn_size]\n",
    "    test = data.iloc[trn_size:]\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manhattan'], dtype='object') Index(['Manhattan'], dtype='object')\n",
      "Index(['Bronx', 'Brooklyn', 'Queens', 'StatenIsland', 'Manhattan'], dtype='object') Index(['Bronx', 'Brooklyn', 'Queens', 'StatenIsland', 'Manhattan'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def data_preparation(data):\n",
    "    # Missing value \n",
    "    data: DataFrame = data.dropna(how=\"any\", inplace=False) \n",
    "    # Train/test split\n",
    "    train, test = dataframe_train_test_split(data)   \n",
    "    \n",
    "    # Scaling\n",
    "    transf: MinMaxScaler = MinMaxScaler(feature_range=(0, 1), copy=True).fit(train)\n",
    "    train_scaled = DataFrame(transf.transform(train), index=train.index, columns=train.columns)\n",
    "    test_scaled = DataFrame(transf.transform(test), index=test.index, columns=test.columns) \n",
    "\n",
    "    # Smoothing\n",
    "    WIN_SIZE = 10\n",
    "    train_smooth: Series = train_scaled.rolling(window=WIN_SIZE).mean()\n",
    "    train_smooth = train_smooth.dropna()\n",
    "\n",
    "    # Differentiation\n",
    "    train_diff: Series = train_smooth.diff()\n",
    "    train_diff = train_diff.dropna()\n",
    "    test_diff: Series = test_scaled.diff()\n",
    "    test_diff = test_diff.dropna()\n",
    "\n",
    "    return train_diff, test_diff\n",
    "    \n",
    "    \n",
    "train_target, test_target = data_preparation(data)\n",
    "\n",
    "train_all, test_all = data_preparation(all_data)\n",
    "\n",
    "\n",
    "print(train_target.columns, test_target.columns)\n",
    "print(train_all.columns, test_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import no_grad, tensor\n",
    "from torch.nn import LSTM, Linear, Module, MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "def prepare_dataset_for_lstm(series, seq_length: int = 4):\n",
    "    setX: list = []\n",
    "    setY: list = []\n",
    "    for i in range(len(series) - seq_length):\n",
    "        past = series[i : i + seq_length]\n",
    "        future = series[i + 1 : i + seq_length + 1]\n",
    "        setX.append(past)\n",
    "        setY.append(future)\n",
    "    return tensor(setX), tensor(setY)\n",
    "\n",
    "\n",
    "class DS_LSTM(Module):\n",
    "    def __init__(self, train, input_size: int = 1, hidden_size: int = 50, num_layers: int = 1, length: int = 4):\n",
    "        super().__init__()\n",
    "        self.lstm = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = Linear(hidden_size, 1)\n",
    "        self.optimizer = Adam(self.parameters())\n",
    "        self.loss_fn = MSELoss()\n",
    "\n",
    "        trnX, trnY = prepare_dataset_for_lstm(train, seq_length=length)\n",
    "        self.loader = DataLoader(TensorDataset(trnX, trnY), shuffle=True, batch_size=len(train) // 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self):\n",
    "        self.train()\n",
    "        for batchX, batchY in self.loader:\n",
    "            y_pred = self(batchX)\n",
    "            loss = self.loss_fn(y_pred, batchY)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        with no_grad():\n",
    "            y_pred = self(X)\n",
    "        return y_pred[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Queens</th>\n",
       "      <th>StatenIsland</th>\n",
       "      <th>Manhattan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-11</th>\n",
       "      <td>0.053620</td>\n",
       "      <td>0.034496</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0.021698</td>\n",
       "      <td>0.033069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-12</th>\n",
       "      <td>0.045023</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.047554</td>\n",
       "      <td>0.019811</td>\n",
       "      <td>0.037030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-13</th>\n",
       "      <td>0.019910</td>\n",
       "      <td>0.019767</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.020594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-14</th>\n",
       "      <td>-0.013801</td>\n",
       "      <td>-0.025581</td>\n",
       "      <td>-0.019293</td>\n",
       "      <td>-0.015094</td>\n",
       "      <td>-0.018812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-15</th>\n",
       "      <td>-0.059729</td>\n",
       "      <td>-0.043798</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.033962</td>\n",
       "      <td>-0.046337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-21</th>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.009109</td>\n",
       "      <td>0.013043</td>\n",
       "      <td>-0.006604</td>\n",
       "      <td>0.012277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-22</th>\n",
       "      <td>-0.002941</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>-0.015094</td>\n",
       "      <td>-0.006139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-23</th>\n",
       "      <td>-0.006787</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>-0.005660</td>\n",
       "      <td>-0.008713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-24</th>\n",
       "      <td>-0.006787</td>\n",
       "      <td>-0.019186</td>\n",
       "      <td>-0.015761</td>\n",
       "      <td>-0.015094</td>\n",
       "      <td>-0.017030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-25</th>\n",
       "      <td>-0.010181</td>\n",
       "      <td>-0.008333</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>-0.006604</td>\n",
       "      <td>-0.005149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5249 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Bronx  Brooklyn    Queens  StatenIsland  Manhattan\n",
       "Date                                                             \n",
       "2006-01-11  0.053620  0.034496  0.020380      0.021698   0.033069\n",
       "2006-01-12  0.045023  0.014341  0.047554      0.019811   0.037030\n",
       "2006-01-13  0.019910  0.019767  0.015761      0.011321   0.020594\n",
       "2006-01-14 -0.013801 -0.025581 -0.019293     -0.015094  -0.018812\n",
       "2006-01-15 -0.059729 -0.043798 -0.039402     -0.033962  -0.046337\n",
       "...              ...       ...       ...           ...        ...\n",
       "2020-05-21  0.006561  0.009109  0.013043     -0.006604   0.012277\n",
       "2020-05-22 -0.002941  0.003101  0.006250     -0.015094  -0.006139\n",
       "2020-05-23 -0.006787 -0.015504 -0.007065     -0.005660  -0.008713\n",
       "2020-05-24 -0.006787 -0.019186 -0.015761     -0.015094  -0.017030\n",
       "2020-05-25 -0.010181 -0.008333  0.004348     -0.006604  -0.005149\n",
       "\n",
       "[5249 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_all.reset_index(drop=True, inplace=True)\n",
    "train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_series = train_all.values.astype(\"float32\")\n",
    "test_all_series = test_all.values.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = DS_LSTM(train_all_series, input_size=5, hidden_size=50, num_layers=1)\n",
    "loss = model.fit()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq length=2 hidden_units=25 nr_episodes=0 0.0071566104888916016\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from matplotlib.pyplot import figure, savefig, subplots\n",
    "\n",
    "\n",
    "def lstm_study(train, test, nr_episodes: int = 1000, measure: str = \"R2\"):\n",
    "    sequence_size = [2, 4, 8]\n",
    "    nr_hidden_units = [25, 50, 100]\n",
    "\n",
    "    step: int = nr_episodes // 10\n",
    "    episodes = [1] + list(range(0, nr_episodes + 1, step))[1:]\n",
    "    flag = measure == \"R2\" or measure == \"MAPE\"\n",
    "    best_model = None\n",
    "    best_params: dict = {\"name\": \"LSTM\", \"metric\": measure, \"params\": ()}\n",
    "    best_performance: float = -100000\n",
    "\n",
    "    _, axs = subplots(1, len(sequence_size), figsize=(len(sequence_size) * HEIGHT, HEIGHT))\n",
    "\n",
    "    for i in range(len(sequence_size)):\n",
    "        length = sequence_size[i]\n",
    "        tstX, tstY = prepare_dataset_for_lstm(test, seq_length=length)\n",
    "\n",
    "        values = {}\n",
    "        for hidden in nr_hidden_units:\n",
    "            yvalues = []\n",
    "            model = DS_LSTM(train, hidden_size=hidden)\n",
    "            for n in range(0, nr_episodes + 1):\n",
    "                model.fit()\n",
    "                if n % step == 0:\n",
    "                    prd_tst = model.predict(tstX)\n",
    "                    eval: float = FORECAST_MEASURES[measure](test[length:], prd_tst)\n",
    "                    print(f\"seq length={length} hidden_units={hidden} nr_episodes={n}\", eval)\n",
    "                    if eval > best_performance and abs(eval - best_performance) > DELTA_IMPROVE:\n",
    "                        best_performance: float = eval\n",
    "                        best_params[\"params\"] = (length, hidden, n)\n",
    "                        best_model = deepcopy(model)\n",
    "                    yvalues.append(eval)\n",
    "            values[hidden] = yvalues\n",
    "        plot_multiline_chart(\n",
    "            episodes,\n",
    "            values,\n",
    "            ax=axs[i],\n",
    "            title=f\"LSTM seq length={length} ({measure})\",\n",
    "            xlabel=\"nr episodes\",\n",
    "            ylabel=measure,\n",
    "            percentage=flag,\n",
    "        )\n",
    "    print(\n",
    "        f\"LSTM best results achieved with length={best_params['params'][0]} hidden_units={best_params['params'][1]} and nr_episodes={best_params['params'][2]}) ==> measure={best_performance:.2f}\"\n",
    "    )\n",
    "    return best_model, best_params\n",
    "\n",
    "measure: str = \"R2\"\n",
    "\n",
    "train = train_target.values.astype(\"float32\")\n",
    "test = test_target.values.astype(\"float32\")\n",
    "\n",
    "best_model, best_params = lstm_study(train, test, nr_episodes=3000, measure=measure)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
