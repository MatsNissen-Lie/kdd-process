{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARREST_KEY</th>\n",
       "      <th>ARREST_DATE</th>\n",
       "      <th>PD_CD</th>\n",
       "      <th>PD_DESC</th>\n",
       "      <th>KY_CD</th>\n",
       "      <th>OFNS_DESC</th>\n",
       "      <th>LAW_CODE</th>\n",
       "      <th>LAW_CAT_CD</th>\n",
       "      <th>ARREST_BORO</th>\n",
       "      <th>ARREST_PRECINCT</th>\n",
       "      <th>JURISDICTION_CODE</th>\n",
       "      <th>AGE_GROUP</th>\n",
       "      <th>PERP_SEX</th>\n",
       "      <th>PERP_RACE</th>\n",
       "      <th>X_COORD_CD</th>\n",
       "      <th>Y_COORD_CD</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32311380</td>\n",
       "      <td>2007-06-18</td>\n",
       "      <td>511.0</td>\n",
       "      <td>CONTROLLED SUBSTANCE, POSSESSION 7</td>\n",
       "      <td>235.0</td>\n",
       "      <td>DANGEROUS DRUGS</td>\n",
       "      <td>PL 2200300</td>\n",
       "      <td>M</td>\n",
       "      <td>Q</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18-24</td>\n",
       "      <td>M</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192799737</td>\n",
       "      <td>2019-01-26</td>\n",
       "      <td>177.0</td>\n",
       "      <td>SEXUAL ABUSE</td>\n",
       "      <td>116.0</td>\n",
       "      <td>SEX CRIMES</td>\n",
       "      <td>PL 1306503</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45-64</td>\n",
       "      <td>M</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>1000555.0</td>\n",
       "      <td>230994.0</td>\n",
       "      <td>40.800694</td>\n",
       "      <td>-73.941109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193260691</td>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PL 2203400</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25-44</td>\n",
       "      <td>M</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>986685.0</td>\n",
       "      <td>215375.0</td>\n",
       "      <td>40.757839</td>\n",
       "      <td>-73.991212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149117452</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>153.0</td>\n",
       "      <td>RAPE 3</td>\n",
       "      <td>104.0</td>\n",
       "      <td>RAPE</td>\n",
       "      <td>PL 1302503</td>\n",
       "      <td>F</td>\n",
       "      <td>K</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25-44</td>\n",
       "      <td>M</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>998032.0</td>\n",
       "      <td>175598.0</td>\n",
       "      <td>40.648650</td>\n",
       "      <td>-73.950336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190049060</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>157.0</td>\n",
       "      <td>RAPE 1</td>\n",
       "      <td>104.0</td>\n",
       "      <td>RAPE</td>\n",
       "      <td>PL 1303501</td>\n",
       "      <td>F</td>\n",
       "      <td>K</td>\n",
       "      <td>77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25-44</td>\n",
       "      <td>M</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>1003606.0</td>\n",
       "      <td>185050.0</td>\n",
       "      <td>40.674583</td>\n",
       "      <td>-73.930222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ARREST_KEY ARREST_DATE  PD_CD                             PD_DESC  KY_CD  \\\n",
       "0    32311380  2007-06-18  511.0  CONTROLLED SUBSTANCE, POSSESSION 7  235.0   \n",
       "1   192799737  2019-01-26  177.0                        SEXUAL ABUSE  116.0   \n",
       "2   193260691  2019-02-06    NaN                                 NaN    NaN   \n",
       "3   149117452  2016-01-06  153.0                              RAPE 3  104.0   \n",
       "4   190049060  2018-11-15  157.0                              RAPE 1  104.0   \n",
       "\n",
       "         OFNS_DESC    LAW_CODE LAW_CAT_CD ARREST_BORO  ARREST_PRECINCT  \\\n",
       "0  DANGEROUS DRUGS  PL 2200300          M           Q               27   \n",
       "1       SEX CRIMES  PL 1306503          F           M               25   \n",
       "2              NaN  PL 2203400          F           M               14   \n",
       "3             RAPE  PL 1302503          F           K               67   \n",
       "4             RAPE  PL 1303501          F           K               77   \n",
       "\n",
       "   JURISDICTION_CODE AGE_GROUP PERP_SEX PERP_RACE  X_COORD_CD  Y_COORD_CD  \\\n",
       "0                1.0     18-24        M     BLACK         NaN         NaN   \n",
       "1                0.0     45-64        M     BLACK   1000555.0    230994.0   \n",
       "2                0.0     25-44        M   UNKNOWN    986685.0    215375.0   \n",
       "3                0.0     25-44        M     BLACK    998032.0    175598.0   \n",
       "4                0.0     25-44        M     BLACK   1003606.0    185050.0   \n",
       "\n",
       "    Latitude  Longitude  \n",
       "0        NaN        NaN  \n",
       "1  40.800694 -73.941109  \n",
       "2  40.757839 -73.991212  \n",
       "3  40.648650 -73.950336  \n",
       "4  40.674583 -73.930222  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Processing each task\n",
    "from numpy import ndarray\n",
    "from pandas import DataFrame, read_csv\n",
    "from matplotlib.pyplot import savefig, show, figure\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add the project directory to sys.path\n",
    "project_dir = Path.cwd().parent.parent  # Adjust as needed to point to your project root\n",
    "\n",
    "# Import the module\n",
    "from utils.dslabs_functions import get_variable_types, encode_cyclic_variables, dummify\n",
    "from utils.data_loader import DataLoader\n",
    "\n",
    "dataloader = DataLoader()\n",
    "data, target = dataloader.get_security_classification_dataset_and_target()\n",
    "# data: DataFrame = read_csv(\"data/stroke_mvi.csv\", index_col=\"id\", na_values=\"\")\n",
    "vars: dict[str, list] = get_variable_types(data)\n",
    "\n",
    "yes_no: dict[str, int] = {\"no\": 0, \"No\": 0, \"yes\": 1, \"Yes\": 1}\n",
    "residence_type_values: dict[str, int] = {\"Rural\": 0, \"Urban\": 1}\n",
    "\n",
    "encoding: dict[str, dict[str, int]] = {\n",
    "    \"Residence_type\": residence_type_values,\n",
    "    \"hypertension\": yes_no,\n",
    "    \"heart_disease\": yes_no,\n",
    "    \"ever_married\": yes_no,\n",
    "    \"stroke\": yes_no,\n",
    "}\n",
    "df: DataFrame = data.replace(encoding, inplace=False)\n",
    "df.head()\n",
    "# age\tavg_glucose_level\tbmi\tgender\twork_type\tsmoking_status\thypertension\theart_disease\tever_married\tResidence_type\tstroke\n",
    "# id\t\t\t\t\t\t\t\t\t\t\t\n",
    "# 9046\t67.0\t228.69\t36.600000\tMale\tPrivate\tformerly smoked\t0\t1\t1\t1\t1\n",
    "# 51676\t61.0\t202.21\t28.893237\tFemale\tSelf-employed\tnever smoked\t0\t0\t1\t0\t1\n",
    "# 31112\t80.0\t105.92\t32.500000\tMale\tPrivate\tnever smoked\t0\t1\t1\t0\t1\n",
    "# 60182\t49.0\t171.23\t34.400000\tFemale\tPrivate\tsmokes\t0\t0\t1\t1\t1\n",
    "# 1665\t79.0\t174.12\t24.000000\tFemale\tSelf-employed\tnever smoked\t1\t0\t1\t0\t1\n",
    "# In the code above, we encoded all the binary variables, since the order among the values is irrelevant. Naturally, we could have chosen any order among the values, but in that case we would loose some information, which consequently would bias the training of models.\n",
    "\n",
    "# In order to choose the order to consider for each variable, we may start by collecting the individual values for each symbolic var.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for v in vars[\"symbolic\"]:\n",
    "    print(v, data[v].unique())\n",
    "# gender ['Male' 'Female' 'Other']\n",
    "# work_type ['Private' 'Self-employed' 'Govt_job' 'children' 'Never_worked']\n",
    "# smoking_status ['formerly smoked' 'never smoked' 'smokes']\n",
    "# Unexpectadly, the gender variable presents 3 different values, which makes it non-binary. We opt to code Female as 0, Male as 2, and Other as 1, considering it represents someone in between, meaning the value shouldn't be closer to any of the traditional values.\n",
    "\n",
    "gender_values: dict[str, int] = {\"Female\": 0, \"Other\": 1, \"Male\": 2}\n",
    "work_values: dict[str, int] = {\n",
    "    \"children\": 0,\n",
    "    \"Never_worked\": 1,\n",
    "    \"Self-employed\": 2,\n",
    "    \"Private\": 3,\n",
    "    \"Govt_job\": 4,\n",
    "}\n",
    "status_values: dict[str, int] = {\"never smoked\": 0, \"formerly smoked\": 1, \"smokes\": 2}\n",
    "\n",
    "encoding: dict[str, dict[str, int]] = {\n",
    "    \"gender\": gender_values,\n",
    "    \"work_type\": work_values,\n",
    "    \"smoking_status\": status_values,\n",
    "}\n",
    "\n",
    "df: DataFrame = df.replace(encoding, inplace=False)\n",
    "df.head()\n",
    "# age\tavg_glucose_level\tbmi\tgender\twork_type\tsmoking_status\thypertension\theart_disease\tever_married\tResidence_type\tstroke\n",
    "# id\t\t\t\t\t\t\t\t\t\t\t\n",
    "# 9046\t67.0\t228.69\t36.600000\t2\t3\t1\t0\t1\t1\t1\t1\n",
    "# 51676\t61.0\t202.21\t28.893237\t0\t2\t0\t0\t0\t1\t0\t1\n",
    "# 31112\t80.0\t105.92\t32.500000\t2\t3\t0\t0\t1\t1\t0\t1\n",
    "# 60182\t49.0\t171.23\t34.400000\t0\t3\t2\t0\t0\t1\t1\t1\n",
    "# 1665\t79.0\t174.12\t24.000000\t0\t2\t0\t1\t0\t1\t0\t1\n",
    "# The logic for the rest of the variables shall be similar. Of course, if we have domain knowledge the choice of the order is natural, and there shouldn't be any doubt about it. Otherwise, we need to pick an order that seems to make sense in helping to descriminate among the class variables.\n",
    "\n",
    "# The smoking_status variable is an example of a situation where common sense is everything we need. Never having smoked (never smoked) aligns more closely with having quit smoking (formerly smoked) than actively smoking (smokes).\n",
    "\n",
    "# Cyclic variables\n",
    "# Among the ordinal variables there are some that instead of having a sequential order, show a cyclic one. Examples of these are season and day of the week.\n",
    "\n",
    "# In these cases, there is no right choice to use as the first or the last one, and so we need a different strategy to encode them.\n",
    "\n",
    "# The common methods applied nowadays to encode each one of these variables is to create two variables per each one, using trigonometric functions to simulate an angle. Say for a var variable we create two new variables to encode it - var_sin and var_cos.\n",
    "\n",
    "# In this manner, if var assumes a value x between 0 and x_max, then var_sin becomes x_sin and var_cos becomes x_cos given below.\n",
    "\n",
    "# No description has been provided for this image\n",
    "# In order to do so, we just need to map the original values from 0 to x_max to values between 0 and (2pi * x / x_max).\n",
    "\n",
    "from math import pi, sin, cos\n",
    "\n",
    "data: DataFrame = read_csv(\n",
    "    \"data/algae.csv\",\n",
    "    index_col=\"date\",\n",
    "    na_values=\"\",\n",
    "    parse_dates=True,\n",
    "    infer_datetime_format=True,\n",
    ")\n",
    "\n",
    "season_val: dict[str, float] = {\n",
    "    \"spring\": 0,\n",
    "    \"summer\": pi / 2,\n",
    "    \"autumn\": pi,\n",
    "    \"winter\": -pi / 2,\n",
    "}\n",
    "lov: dict[str, int] = {\"low\": 0, \"medium\": 1, \"high\": 2}\n",
    "encoding: dict[str, dict] = {\n",
    "    \"river_depth\": lov,\n",
    "    \"fluid_velocity\": lov,\n",
    "    \"season\": season_val,\n",
    "}\n",
    "\n",
    "data = data.replace(encoding)\n",
    "data.head()\n",
    "# pH\tOxygen\tChloride\tNitrates\tAmmonium\tOrthophosphate\tPhosphate\tChlorophyll\tfluid_velocity\triver_depth\tseason\n",
    "# date\t\t\t\t\t\t\t\t\t\t\t\n",
    "# 2018-09-30\t8.10\t11.4\t40.02\t5.33\t346.67\t125.67\t187.06\t15.6\t1\t0\t3.141593\n",
    "# 2018-10-05\t8.06\t9.0\t55.35\t10.42\t233.70\t58.22\t97.58\t10.5\t1\t0\t3.141593\n",
    "# 2018-10-07\t8.05\t10.6\t59.07\t4.99\t205.67\t44.67\t77.43\t6.9\t2\t0\t3.141593\n",
    "# 2018-10-09\t7.55\t11.5\t4.70\t1.32\t14.75\t4.25\t98.25\t1.1\t2\t0\t3.141593\n",
    "# 2018-10-11\t7.75\t10.3\t32.92\t2.94\t42.00\t16.00\t40.00\t7.6\t2\t0\t3.141593\n",
    "# and then create the two new variables from the angle.\n",
    "\n",
    "def encode_cyclic_variables(data: DataFrame, vars: list[str]) -> None:\n",
    "    for v in vars:\n",
    "        x_max: float | int = max(data[v])\n",
    "        data[v + \"_sin\"] = data[v].apply(lambda x: round(sin(2 * pi * x / x_max), 3))\n",
    "        data[v + \"_cos\"] = data[v].apply(lambda x: round(cos(2 * pi * x / x_max), 3))\n",
    "    return\n",
    "\n",
    "\n",
    "data: DataFrame | None = encode_cyclic_variables(data, [\"season\"])\n",
    "if data is not None:\n",
    "    data.head()\n",
    "# Dummification or One-hot Encoding\n",
    "# Dealing with nominal variables is another story. Indeed, by definition there is no order among the values assumed by the variable. When after exploring all possible perspectives, we are not able to specify an acceptable order among those variables the only solution is dummification.\n",
    "\n",
    "# This consists on creating a new variable for each possible value from the original one, removing it from the dataset.\n",
    "\n",
    "# Note, however, that a small number of values leads to the creation of several new variables, creating a much sparser dataset. And so, we shall avoid it as much as possible.\n",
    "\n",
    "# Additionaly, do not dummify the class variable, since it will transform a simple multi label classification problem into a multi class problem.\n",
    "\n",
    "# In order to apply dummification, we can make use of the OneHotEncoder from the package sklearn.preprocessing. The pandas.DataFrame.getDummies is much less interesting since it isn't able to apply the same encoder to different parts of a dataset, while the first one is.\n",
    "\n",
    "# For example, after dummifying the algae dataframe, we get a new one with 18 variables, instead of the 11 original ones, since each one of the three symbolic variables had three different values.\n",
    "\n",
    "# As we saw, we could have considered them as ordinal or cyclic and avoid the increasing of dimensionality.\n",
    "\n",
    "from numpy import ndarray\n",
    "from pandas import DataFrame, read_csv, concat\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def dummify(df: DataFrame, vars_to_dummify: list[str]) -> DataFrame:\n",
    "    other_vars: list[str] = [c for c in df.columns if not c in vars_to_dummify]\n",
    "\n",
    "    enc = OneHotEncoder(\n",
    "        handle_unknown=\"ignore\", sparse_output=False, dtype=\"bool\", drop=\"if_binary\"\n",
    "    )\n",
    "    trans: ndarray = enc.fit_transform(df[vars_to_dummify])\n",
    "\n",
    "    new_vars: ndarray = enc.get_feature_names_out(vars_to_dummify)\n",
    "    dummy = DataFrame(trans, columns=new_vars, index=df.index)\n",
    "\n",
    "    final_df: DataFrame = concat([df[other_vars], dummy], axis=1)\n",
    "    return final_df\n",
    "\n",
    "\n",
    "data: DataFrame = read_csv(\n",
    "    \"data/algae.csv\", index_col=\"date\", na_values=\"\", parse_dates=True, dayfirst=True\n",
    ")\n",
    "vars: list[str] = [\"river_depth\", \"fluid_velocity\", \"season\"]\n",
    "df: DataFrame = dummify(data, vars)\n",
    "df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
