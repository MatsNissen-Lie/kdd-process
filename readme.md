# Data Science labs

## Table of Contents

- [Access the Code for Analysis](#access-the-code-for-analysis)
- [Datasets Used in the Project](#datasets-used-in-the-project)
  - [Classification Datasets](#classification-datasets)
  - [Forecasting Datasets](#forecasting-datasets)
- [File Structure](#file-structure)
  - [Analysis](#analysis)
  - [Utilities](#utilities)
- [Schedule](#schedule)
- [Set Up LaTeX for Writing Reports](#set-up-latex-for-writing-reports)
  - [Step 1: Install TeX Live with Homebrew](#step-1-install-tex-live-with-homebrew)
  - [Step 2: Install the LaTeX Workshop Extension](#step-2-install-the-latex-workshop-extension)
  - [Step 3: Configure LaTeX Workshop](#step-3-configure-latex-workshop)
  - [Step 5: Compile Your LaTeX Document](#step-5-compile-your-latex-document)

## Access the Code for Analysis

All the code used for the analysis can be found [here](https://web.ist.utl.pt/~claudia.antunes/DSLabs/#).

It should be copied and applied to the datasets. Our job is to analyze the plots, provide insights and write a lab report.

This resource contains additional details and examples that complement the work in this project.

## Datasets Used in the Project

This project utilizes several datasets for classification and forecasting tasks. The datasets are organized based on their focus on either **economic** or **security** topics.

### Classification Datasets

- `c_e_class_financial_distress.csv`: A dataset focused on classifying financial distress (economic).
- `c_s_class_ny_arrests.csv`: A dataset focused on classifying arrests in New York (security).

### Forecasting Datasets

- `f_e_forecast_gdp_europe.csv`: A dataset for forecasting GDP trends in Europe (economic).
- `f_s_forecast_ny_arrests.csv`: A dataset for forecasting arrest trends in New York (security).

All datasets are stored in the `data/` directory and are referenced accordingly in the project code.

|                    | Security domain                           | Economical domain                    |
| ------------------ | ----------------------------------------- | ------------------------------------ |
| **Classification** | [dataset](#)                              | [dataset](#)                         |
|                    | target = **LAW_CAT_CD** (binary variable) | target = **CLASS** (binary variable) |
| **Forecasting**    | [dataset](#)                              | [dataset](#)                         |
|                    | target = **Manhattan**                    | target = **GDP**                     |

## File Structure

The `src` directory is organized to align with the modular structure of the project, separating profiling tasks for classification and forecasting datasets. Below is an updated directory structure:

```plaintext
src/
â”œâ”€â”€ module_1_profiling/
â”‚   â”œâ”€â”€ classification_profiling/
â”‚   â”œâ”€â”€ forecasting_profiling/
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ module_2_preparation/
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ module_3_feature_engineering/
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ module_4_classification/
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ module_5_prediction/
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ economic/
â”‚   â”œâ”€â”€ security/
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ utils/
    â”œâ”€â”€ data_loader.py
    â”œâ”€â”€ preprocess.py
    â””â”€â”€ __init__.py
```

For a detailed breakdown of the project structure, see the [Full File Structure](#full-file-structure) in the Appendix.

<!-- ### Modules -->

<!-- #### Module 1: Data Profiling

The `module_1_profiling/` folder is divided into subfolders for **classification** and **forecasting** profiling:

- **`classification_profiling/`**:
  - `dimensionality.py`: Analyze the dimensions of classification datasets.
  - `distribution.py`: Study data distributions for classification tasks.
  - `granularity.py`: Assess the granularity of classification datasets.
  - `sparsity.py`: Measure sparsity in classification datasets.
- **`forecasting_profiling/`**:
  - `dimensionality.py`: Analyze the dimensions of forecasting datasets.
  - `distribution.py`: Study data distributions for forecasting tasks.
  - `granularity.py`: Assess the granularity of forecasting datasets.
  - `sparsity.py`: Measure sparsity in forecasting datasets.

#### Module 2: Data Preparation

The `module_2_preparation/` folder includes functions for data preparation, such as handling missing values, outlier removal, and scaling.

#### Module 3: Feature Engineering

The `module_3_feature_engineering/` folder includes scripts for:

- Feature selection
- Feature extraction
- Feature generation

#### Module 4: Classification

The `module_4_classification/` folder provides algorithms and evaluation methods for classification tasks.

#### Module 5: Prediction

The `module_5_prediction/` folder provides algorithms and evaluation methods for forecasting tasks.

--- -->

### Analysis

The `analysis/` folder applies the modules to the datasets:

- **`economic/`**: Scripts for classification and forecasting analysis on economic datasets.
- **`security/`**: Scripts for classification and forecasting analysis on security datasets.

---

### Utilities

The `utils/` folder contains helper scripts:

<!-- - `data_loader.py`: Functions for loading datasets. -->

- `preprocess.py`: Common preprocessing utilities.

## Schedule

| Week               | Task                                                      | Details                                                                                                                          |
| ------------------ | --------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| 1st Week           | Team registration, Software installation                  | -                                                                                                                                |
| 2nd Week - Eval L1 | Data profiling                                            | Data dimensionality<br>Data granularity<br>Data distribution<br>Data sparsity                                                    |
| 3rd Week - Eval L2 | Data preparation                                          | Variables encoding<br>Missing values and outliers<br>Scaling transformation<br>Data balancing                                    |
| 4th Week - Eval L3 | Feature selection, Performance and Overfitting evaluation | Naive Bayes study<br>KNN study<br>Decision trees study                                                                           |
| 5th Week - Eval L4 | Feature selection, Performance and Overfitting evaluation | Random forests<br>Multi-layer perceptron<br>Gradient boosting                                                                    |
| 6th Week - Eval L5 | Time series                                               | Profiling<br>Transformation<br>Forecasting: Persistence model, Simple average, Rolling mean, Exponential smoothing, ARIMA, LSTMs |

## Set Up LaTeX for Writing Reports

### Step 1: Install TeX Live with Homebrew

This is for mac users with brew only. If you are using windows or linux, you can install [TeX Live](https://www.tug.org/texlive/) directly from the website (not recommende, you should get a mac and homebrewğŸ).

1. Open your terminal.

2. Run the following command:

   ```bash
   brew install --cask mactex-no-gui
   ```

   - **`mactex-no-gui`** installs TeX Live without the GUI applications (e.g., TeXShop), which is a lighter version (~3GB instead of ~4.4GB).
   - If you want the full MacTeX suite (with GUI tools), use:

     ```bash
     brew install --cask mactex
     ```

### Step 2: Install the LaTeX Workshop Extension

1. Open Visual Studio Code.
2. Navigate to the Extensions view by pressing `Ctrl+Shift+X` (Windows/Linux) or `Cmd+Shift+X` (macOS).
3. Search for **LaTeX Workshop** and click **Install**.

The **LaTeX Workshop** extension provides features such as:

- Syntax highlighting
- Live preview
- PDF syncing

Hereâ€™s the formatted version for your README:

### Step 3: Configure LaTeX Workshop

LaTeX Workshop automatically builds the PDF and supports live preview by default. However, you may want to customize some settings:

1. Open the settings JSON in VS Code:

   - Press `Ctrl+,` (Windows/Linux) or `Cmd+,` (macOS), then search for "settings.json."

2. Add or modify the following settings:

   ```json
   {
     "latex-workshop.latex.autoBuild.run": "onSave",
     "latex-workshop.view.pdf.viewer": "tab"
   }
   ```

   - `"onSave"`: Automatically compiles the project whenever you save your `.tex` file.
   - `"tab"`: Displays the PDF in an internal VS Code tab. You can use `"browser"` instead to open the PDF in an external browser.

### Step 5: Compile Your LaTeX Document

1. Save your `.tex` file (`Ctrl+S` on Windows/Linux or `Cmd+S` on macOS).
2. LaTeX Workshop will automatically compile the document.
3. The PDF viewer will reload whenever a new version of the document is compiled.

## Appendix

### Full File Structure

The complete file structure for this project can be found below:

```plaintext
src/
â”œâ”€â”€ module_1_profiling/
â”‚ â”œâ”€â”€ classification_profiling/
â”‚ â”‚ â”œâ”€â”€ dimensionality.py
â”‚ â”‚ â”œâ”€â”€ distribution.py
â”‚ â”‚ â”œâ”€â”€ granularity.py
â”‚ â”‚ â”œâ”€â”€ sparsity.py
â”‚ â”‚ â””â”€â”€ **init**.py
â”‚ â”œâ”€â”€ forecasting_profiling/
â”‚ â”‚ â”œâ”€â”€ dimensionality.py
â”‚ â”‚ â”œâ”€â”€ distribution.py
â”‚ â”‚ â”œâ”€â”€ granularity.py
â”‚ â”‚ â”œâ”€â”€ sparsity.py
â”‚ â”‚ â””â”€â”€ **init**.py
â”‚ â””â”€â”€ **init**.py
â”œâ”€â”€ module_2_preparation/
â”‚ â”œâ”€â”€ methodology.py
â”‚ â”œâ”€â”€ encoding.py
â”‚ â”œâ”€â”€ missing_values.py
â”‚ â”œâ”€â”€ outliers.py
â”‚ â”œâ”€â”€ scaling.py
â”‚ â”œâ”€â”€ balancing.py
â”‚ â”œâ”€â”€ discretization.py
â”‚ â””â”€â”€ **init**.py
â”œâ”€â”€ module_3_feature_engineering/
â”‚ â”œâ”€â”€ feature_selection.py
â”‚ â”œâ”€â”€ feature_extraction.py
â”‚ â”œâ”€â”€ feature_generation.py
â”‚ â””â”€â”€ **init**.py
â”œâ”€â”€ module_4_classification/
â”‚ â”œâ”€â”€ evaluation.py
â”‚ â”œâ”€â”€ naive_bayes.py
â”‚ â”œâ”€â”€ knn.py
â”‚ â”œâ”€â”€ decision_trees.py
â”‚ â”œâ”€â”€ logistic_regression.py
â”‚ â”œâ”€â”€ neural_networks.py
â”‚ â”œâ”€â”€ svm.py
â”‚ â”œâ”€â”€ random_forests.py
â”‚ â”œâ”€â”€ gradient_boosting.py
â”‚ â””â”€â”€ **init**.py
â”œâ”€â”€ module_5_prediction/
â”‚ â”œâ”€â”€ evaluation.py
â”‚ â”œâ”€â”€ regression_trees.py
â”‚ â”œâ”€â”€ logistic_regression.py
â”‚ â”œâ”€â”€ neural_networks.py
â”‚ â”œâ”€â”€ random_forests.py
â”‚ â”œâ”€â”€ gradient_boosting.py
â”‚ â””â”€â”€ **init**.py
â”œâ”€â”€ analysis/
â”‚ â”œâ”€â”€ economic/
â”‚ â”‚ â”œâ”€â”€ classification_analysis.py
â”‚ â”‚ â”œâ”€â”€ forecasting_analysis.py
â”‚ â”‚ â””â”€â”€ **init**.py
â”‚ â”œâ”€â”€ security/
â”‚ â”‚ â”œâ”€â”€ classification_analysis.py
â”‚ â”‚ â”œâ”€â”€ forecasting_analysis.py
â”‚ â”‚ â””â”€â”€ **init**.py
â”‚ â””â”€â”€ **init**.py
â””â”€â”€ utils/
â”œâ”€â”€ data_loader.py
â”œâ”€â”€ preprocess.py
â””â”€â”€ **init**.py

```
